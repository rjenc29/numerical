{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix addition using cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numba import cuda, vectorize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@cuda.jit('void(float32[:], float32[:], float32[:])')\n",
    "def cu_add1(a, b, c):\n",
    "    \"\"\"This kernel function will be executed by a thread.\"\"\"\n",
    "    bx = cuda.blockIdx.x # which block in the grid?\n",
    "    bw = cuda.blockDim.x # what is the size of a block?\n",
    "    tx = cuda.threadIdx.x # unique thread ID within a blcok\n",
    "    i = tx + bx * bw\n",
    "\n",
    "    if i > c.size:\n",
    "        return\n",
    "\n",
    "    c[i] = a[i] + b[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<CUDA device 0 'b'GeForce GTX 1060''>\n",
      "Blocks per grid: 4\n",
      "Threads per block: 32\n",
      "[   0.    2.    4.    6.    8.   10.   12.   14.   16.   18.   20.   22.\n",
      "   24.   26.   28.   30.   32.   34.   36.   38.   40.   42.   44.   46.\n",
      "   48.   50.   52.   54.   56.   58.   60.   62.   64.   66.   68.   70.\n",
      "   72.   74.   76.   78.   80.   82.   84.   86.   88.   90.   92.   94.\n",
      "   96.   98.  100.  102.  104.  106.  108.  110.  112.  114.  116.  118.\n",
      "  120.  122.  124.  126.  128.  130.  132.  134.  136.  138.  140.  142.\n",
      "  144.  146.  148.  150.  152.  154.  156.  158.  160.  162.  164.  166.\n",
      "  168.  170.  172.  174.  176.  178.  180.  182.  184.  186.  188.  190.\n",
      "  192.  194.  196.  198.]\n"
     ]
    }
   ],
   "source": [
    "device = cuda.get_current_device()\n",
    "print(device)\n",
    "\n",
    "n = 100\n",
    "\n",
    "# Host memory\n",
    "a = np.arange(n, dtype=np.float32)\n",
    "b = np.arange(n, dtype=np.float32)\n",
    "\n",
    "# Assign equivalent storage on device\n",
    "da = cuda.to_device(a)\n",
    "db = cuda.to_device(b)\n",
    "\n",
    "# Assign storage on device for output\n",
    "dc = cuda.device_array_like(a)\n",
    "\n",
    "# Set up enough threads for kernel\n",
    "tpb = device.WARP_SIZE\n",
    "bpg = int(np.ceil(float(n)/tpb))\n",
    "print('Blocks per grid: {0}'.format(bpg))\n",
    "print('Threads per block: {0}'.format(tpb))\n",
    "\n",
    "# Launch kernel\n",
    "cu_add1[bpg, tpb](da, db, dc)\n",
    "\n",
    "# Transfer output from device to host\n",
    "c = dc.copy_to_host()\n",
    "\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simpler version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@cuda.jit('void(float32[:], float32[:], float32[:])')\n",
    "def cu_add2(a, b, c):\n",
    "    \"\"\"This kernel function will be executed by a thread.\"\"\"\n",
    "    i  = cuda.grid(1)\n",
    "\n",
    "    if i > c.shape[0]:\n",
    "        return\n",
    "\n",
    "    c[i] = a[i] + b[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blocks per grid: 4\n",
      "Threads per block: 32\n",
      "[   0.    2.    4.    6.    8.   10.   12.   14.   16.   18.   20.   22.\n",
      "   24.   26.   28.   30.   32.   34.   36.   38.   40.   42.   44.   46.\n",
      "   48.   50.   52.   54.   56.   58.   60.   62.   64.   66.   68.   70.\n",
      "   72.   74.   76.   78.   80.   82.   84.   86.   88.   90.   92.   94.\n",
      "   96.   98.  100.  102.  104.  106.  108.  110.  112.  114.  116.  118.\n",
      "  120.  122.  124.  126.  128.  130.  132.  134.  136.  138.  140.  142.\n",
      "  144.  146.  148.  150.  152.  154.  156.  158.  160.  162.  164.  166.\n",
      "  168.  170.  172.  174.  176.  178.  180.  182.  184.  186.  188.  190.\n",
      "  192.  194.  196.  198.]\n"
     ]
    }
   ],
   "source": [
    "device = cuda.get_current_device()\n",
    "\n",
    "n = 100\n",
    "a = np.arange(n, dtype=np.float32)\n",
    "b = np.arange(n, dtype=np.float32)\n",
    "c = np.empty_like(a)\n",
    "\n",
    "tpb = device.WARP_SIZE\n",
    "bpg = int(np.ceil(float(n)/tpb))\n",
    "print('Blocks per grid: {0}'.format(bpg))\n",
    "print('Threads per block: {0}'.format(tpb))\n",
    "\n",
    "cu_add2[bpg, tpb](a, b, c)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using vectorize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@vectorize(['int64(int64, int64)',\n",
    "            'float32(float32, float32)',\n",
    "            'float64(float64, float64)'],\n",
    "           target='cuda')\n",
    "def cu_add(a, b):\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0.    2.    4.    6.    8.   10.   12.   14.   16.   18.   20.   22.\n",
      "   24.   26.   28.   30.   32.   34.   36.   38.   40.   42.   44.   46.\n",
      "   48.   50.   52.   54.   56.   58.   60.   62.   64.   66.   68.   70.\n",
      "   72.   74.   76.   78.   80.   82.   84.   86.   88.   90.   92.   94.\n",
      "   96.   98.  100.  102.  104.  106.  108.  110.  112.  114.  116.  118.\n",
      "  120.  122.  124.  126.  128.  130.  132.  134.  136.  138.  140.  142.\n",
      "  144.  146.  148.  150.  152.  154.  156.  158.  160.  162.  164.  166.\n",
      "  168.  170.  172.  174.  176.  178.  180.  182.  184.  186.  188.  190.\n",
      "  192.  194.  196.  198.]\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "a = np.arange(n, dtype=np.float32)\n",
    "b = np.arange(n, dtype=np.float32)\n",
    "c = cu_add(a, b)\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
